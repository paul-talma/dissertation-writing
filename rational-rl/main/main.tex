\documentclass{phil-paper}

\title{Rational Reinforcement Learning}
\author{Paul Talma}

\begin{document}
Reinforcement learning is a set of mathematical and computational tools for handling sequential decision problems.
As a branch of economics and operations research, it is closely related to the study of choice behavior and theories of rational choice in particular.
As a branch of computer science, it sits alongside supervised and unsupervised learning as one of the methodological pillars of machine machine learning.
And as a branch of  cognitive science, it stands as one of the best-confirmed computational analyses of animal behavior, unifying a wide range of observations and enjoying precisely identified neural correlates.
Despite this impressive pedigree, reinforcement learning has garnered little attention from the philosophical community.
This is a shame.
Reinforcement learning can shed light on many questions of philosophical interest, and raises interesting questions of its own.
I will indicate some of these questions below.
I claim that reinforcement learning provides an account of the structure and content of certain mental representations, and that this account reveals surprising features of these representations.
Before explaining this account in any greater detail, I will provide an overview of reinforcement learning and summarize some of the field's key findings.

% Reinforcement learning is a framework for modeling sequential decision-making.
% In addition to its use in cognitive and neural modeling [CITE: gureckis and love], reinforcement learning is one of the foundational machine learning approaches to artificial intelligence.
% According to the ``standard model,'' artificial intelligence aims to design \emph{rational agents}, understood as agents that maximize their expected utility [CITE: Russell and Norvig].
% Reinforcement learning agents do not in general maximize expected utility.
% Instead, they follow a policy learned through experience.
% In favorable circumstances, with a good learning algorithm, and with enough training, the agent learns an approximately optimal policy.
% Nonetheless, reinforcement learners fall short of full Bayesian rationality.
% Do these shortcomings merely reflect the difficulty of building an ideal Bayesian agent---engineering compromises in the face of the intractability of full Bayesian rationality?
% Or can the tools of reinforcement learning be vindicated from within the Bayesian perspective?


% \include{bdt}

% \include{rl-summary}

% \include{connecting-rl-bdt}
\input{rl-know-how.tex}
\input{rl-summary.tex}
\input{advanced-rl.tex}
\include{phil-rl-lit-review}

	
\end{document}

