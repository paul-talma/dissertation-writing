\section{Bounded rationality}

Bounded rationality considers how (if at all) the framework of decision theory should be sensitive to an agent's limitations.
Consider an everyday decision, such as whether to buy eggs while at the grocery store.
According to standard decision theory, one of the actions available to me (say, buying the eggs) maximizes expected utility, and rationality requires that I take this action.\footnote{For ease of exposition, we assume that there is a unique optimal action.}
However, I may not know that this is the case.
Indeed, the expected utility of buying the eggs depends on the complex interaction of a number of factors, such as the number of eggs left in my fridge, the time they were bought, the price of the eggs before me, my expectation concerning the future availability and price of eggs, whether I plan to make recipies involving eggs in the near future, and so on.
Moreover, the expected utility of each other options (in this case, not buying the eggs) likewise depends in a complex way on a suite of other factors, and this utility must also be calculated if I am to figure out which action maximizes expected utility.
If I attempt to perform these calculations while at the store, I am unlikely to finish before closing time.
And if I do finish, I am likely to have made a mistake in one of the many computations I had to perform on the fly, without the assistance of pen and paper.
Thus, if I naively attempt to conform to the demands of standard decision theory, I am likely to end up worse off than if I simply choose the first carton of eggs my eyes land upon, without further consideration of the optimality of my choice.
To that extent, attempting to maximize expected utility appears to be \emph{irrational}.

If I could costlessly and flawlessly determine which action maximizes expected utility, then the situation described in the previous paragraph would clearly not arise: I would simply choose the optimal action.
The issue raised by such examples is that deliberation itself incurs a cost---in time, energy, memory, or other resources---and that this cost is not reflected in the expected utilities of actions.
%TODO: incomplete

For the purposes of this paper, two strands of bounded rationality will be relevant (see Icard (ms.) for an overview of other approaches [CITE: Icard, Resource Rationality]).
The first is the so-called ``ecological rationality'' approach [CITE: Gigerenzer].
Work in this research program often proceeds by choosing a particular bias or heuristic displayed by humans or other creatures, modeling it mathematically, and deriving environmental conditions under which this bias or heuristic is optimal (as judged by traditional criteria).
If the organism's environment satisfies these conditions, the finding is viewed as vindicating the creature's rationality.
The key idea behind ecological rationality is to view heuristics as cheap ways to achieve optimality, whose success depends on cooperation from the environment.

The second strand of relevance is the \emph{resource rationality} approach [CITE: Leider and Griffiths, Griffiths and Tenenbaum, Icard].
On this approach, the creature of interest is characterized as subject to certain computational constraints that either limit the range of algorithms at their disposal for solving a particular problem, or induce a cost for using any particular algorithm.
Then, 
