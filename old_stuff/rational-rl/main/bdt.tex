\section{Bayesian Decision Theory}

The starting point for a general theory of (instrumental) rationality is Bayesian Decision Theory (BDT).
BDT is an intuitively compelling and mathematically precise theory of the interaction between an agent's credences, their utilities, and their decisions.
We do not claim that BDT is the final word concerning rationality.
Rather, we claim that it provides a helpful and promising starting point for thinking about rationality.
In the remainder of this section, we provide an overview of BDT, so as to set the backdrop for our discussion of reinforcement learning.
In brief, BDT models an agent's degrees of uncertainty over states of affairs using the probability calculus.

\subsection{Credences}
One of the central concepts of BDT is that of a \emph{credal state}.
Credal states are states that encode probability distributions.
According to \emph{probabilism}, a rational agent's credal states obey Kolmogorov's probability axioms [CITE: Titlebaum].





Credences are often explicated as \emph{degrees of belief}.
Beliefs are \emph{propositional} mental states.
BDT and reinforcement learning apply to organisms and machines that lack (or in any case are not known to possess) propositional mental states.
For example, [CITE: Rescorla Dog] analyses a dog's hunting behavior in terms BDT.
Crucially, while the dog maintains a probability distribution over mental representations, these representations lack propositional structure (they have a map-like structure).
Thus, the applicability of BDT does not depend on the agent's having propositional capacities.
